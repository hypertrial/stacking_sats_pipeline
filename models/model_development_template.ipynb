{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e318ede0-85ca-454e-bee0-cf9bfa909584",
   "metadata": {},
   "source": [
    "# [Trilemma Foundation](https://www.trilemma.foundation/) x [Strategy](https://www.strategy.com/) Stacking Sats Tournament\n",
    "\n",
    "**Hosted on [Hypertrial.ai](https://www.hypertrial.ai/bitcoin-arena/challenge/bitcoin)**\n",
    "\n",
    "### Model Development Template\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d1d1f-d7b0-4f74-a34b-d6b7c76c6f48",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hypertrial/stacking_sats_challenge/blob/main/tutorials/4.%20Strategy%20Development%20Template.ipynb)\n",
    "\n",
    "A youtube walkthrough of an older (less general) version of this notebook can useful to watch:\n",
    "\n",
    "[![YouTube](https://img.shields.io/badge/Watch%20on-YouTube-red?logo=youtube&logoColor=white)](https://youtu.be/qJp8W83f3Fw?si=Wzo8ORKwFLHhBoM0)\n",
    "\n",
    "This notebook replicates the structure used by the evaluation engine to test all submitted strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… What Youâ€™ll Learn\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "- Understand the **boilerplate code** and what is already provided (e.g. imports, data loading, global config)\n",
    "- Learn where and how to **insert your own strategy logic**\n",
    "- Run **backtests and visualizations** to debug and assess performance\n",
    "- Ensure your submission is **valid, testable, and reproducible**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ What Youâ€™re Expected to Do\n",
    "\n",
    "- **Modify only the user code** inside the provided cell  \n",
    "- Leave all boilerplate (e.g. registration, config, data loading) unchanged\n",
    "- Submit your user code cell for evaluation on [Hypertrial.ai]('https://www.hypertrial.ai/')\n",
    "\n",
    "This structure guarantees consistency, fairness, and ease of comparison across all submitted models.\n",
    "\n",
    "---\n",
    "\n",
    "> âš ï¸ Do not change function names, decorators, or global config values unless explicitly allowed.  \n",
    "> Your entry must adhere to this template to be considered valid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13331a17-f6ba-4890-ba5c-8367ff310fc7",
   "metadata": {},
   "source": [
    "# Model Development Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e7157-8631-44e3-a1d8-6b0026fe62f9",
   "metadata": {},
   "source": [
    "### ğŸš« Boilerplate Code â€” Do Not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš« DO NOT MODIFY: Framework boilerplate cell\n",
    "# ---------------------------\n",
    "# core/config.py\n",
    "# ---------------------------\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Global Variables   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\n",
    "# Back-test date range\n",
    "BACKTEST_START     = '2011-06-01'\n",
    "BACKTEST_END       = '2025-06-01'\n",
    "\n",
    "# Rolling window length (in months)\n",
    "INVESTMENT_WINDOW  = 12\n",
    "\n",
    "# Step frequency for window start-dates: 'Daily', 'Weekly' or 'Monthly'\n",
    "PURCHASE_FREQ      = 'Daily'\n",
    "\n",
    "# Minimum per-period weight (to avoid zero allocations)\n",
    "MIN_WEIGHT         = 1e-5\n",
    "\n",
    "\n",
    "PURCHASE_FREQ_TO_OFFSET = {\n",
    "    'Daily':   '1D',\n",
    "    'Weekly':  '7D',\n",
    "    'Monthly': '1M',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf5720-52f6-4223-a7cc-12a839135007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš« DO NOT MODIFY: Framework boilerplate cell\n",
    "# ---------------------------\n",
    "# Extract BTC data from CoinMetrics and save locally\n",
    "# ---------------------------\n",
    "import logging\n",
    "from io import StringIO  # new import\n",
    "\n",
    "import pandas as pd\n",
    "import requests  # new import\n",
    "\n",
    "try:\n",
    "    from coinmetrics.api_client import CoinMetricsClient\n",
    "except ImportError:\n",
    "    raise ImportError(\"coinmetrics.api_client module is required. Install it via pip:\\n\\n    pip install coinmetrics-api-client\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "def extract_btc_data_to_csv(local_path='btc_data.csv'):\n",
    "    # Coin Metrics BTC CSV (raw GitHub URL)\n",
    "    url = \"https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv\"\n",
    "\n",
    "    # Download the content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # raises an error for bad responses\n",
    "\n",
    "    # Parse CSV content\n",
    "    btc_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "    btc_df['time'] = pd.to_datetime(btc_df['time']).dt.normalize()\n",
    "    btc_df['time'] = btc_df['time'].dt.tz_localize(None)\n",
    "    btc_df.set_index('time', inplace=True)\n",
    "\n",
    "    btc_df.to_csv(local_path)\n",
    "\n",
    "    # Show the df\n",
    "    btc_df\n",
    "\n",
    "btc_df = extract_btc_data_to_csv(\"btc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš« DO NOT MODIFY: Framework boilerplate cell\n",
    "# ---------------------------\n",
    "# core/data.py\n",
    "# ---------------------------\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"btc_data.csv\", index_col=0, parse_dates=True)\n",
    "    df = df.loc[~df.index.duplicated(keep='last')]\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "def validate_price_data(df):\n",
    "    if df.empty or 'PriceUSD' not in df.columns:\n",
    "        raise ValueError(\"Invalid BTC price data.\")\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Index must be datetime.\")\n",
    "\n",
    "# Global Variable to use later\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79861625-945f-40b3-b00e-cc4151f9fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Helper: humanâ€readable rollingâ€window labels           â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def _make_window_label(window_start: pd.Timestamp, window_end: pd.Timestamp) -> str:\n",
    "    \"\"\"\n",
    "    Format \"YYYY-MM-DD â†’ YYYY-MM-DD\" for a rolling window.\n",
    "    \"\"\"\n",
    "    start_str = pd.to_datetime(window_start).strftime(\"%Y-%m-%d\")\n",
    "    end_str   = pd.to_datetime(window_end).strftime(\"%Y-%m-%d\")\n",
    "    return f\"{start_str} â†’ {end_str}\"\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Rollingâ€window SPD computation                         â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def compute_cycle_spd(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute satsâ€perâ€dollar (SPD) stats over rolling windows.\n",
    "\n",
    "    - Uses fullâ€history features (no lookâ€ahead).\n",
    "    - Window length = INVESTMENT_WINDOW months.\n",
    "    - Step every PURCHASE_FREQ.\n",
    "    - Returns a DataFrame indexed by window label, with:\n",
    "        min_sats_per_dollar, max_sats_per_dollar,\n",
    "        uniform_sats_per_dollar, dynamic_sats_per_dollar,\n",
    "        uniform_percentile, dynamic_percentile, excess_percentile.\n",
    "    \"\"\"\n",
    "    # 1) Precompute full-history features & restrict to backtest\n",
    "    full_feat = construct_features(dataframe).loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "    # 2) Window parameters\n",
    "    window_offset  = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step_freq      = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    results = []\n",
    "    for window_start in pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step_freq\n",
    "    ):\n",
    "        window_end  = window_start + window_offset\n",
    "        feat_slice  = full_feat.loc[window_start:window_end]\n",
    "        price_slice = dataframe[\"PriceUSD\"].loc[window_start:window_end]\n",
    "\n",
    "        if price_slice.empty:\n",
    "            continue\n",
    "\n",
    "        label       = _make_window_label(window_start, window_end)\n",
    "        inv_price   = (1.0 / price_slice) * 1e8  # sats per dollar\n",
    "\n",
    "        # Compute weights on this slice\n",
    "        weight_slice = strategy_function(feat_slice)\n",
    "\n",
    "        # Uniform vs. dynamic SPD\n",
    "        uniform_spd = inv_price.mean()\n",
    "        dynamic_spd = (weight_slice * inv_price).sum()\n",
    "\n",
    "        # Min/max for percentile scaling\n",
    "        min_spd = inv_price.min()   # low price â†’ high SPD\n",
    "        max_spd = inv_price.max()   # high price â†’ low SPD\n",
    "        span    = max_spd - min_spd\n",
    "\n",
    "        uniform_pct = (uniform_spd - min_spd) / span * 100\n",
    "        dynamic_pct = (dynamic_spd - min_spd) / span * 100\n",
    "\n",
    "        results.append({\n",
    "            \"window\":                   label,\n",
    "            \"min_sats_per_dollar\":      min_spd,\n",
    "            \"max_sats_per_dollar\":      max_spd,\n",
    "            \"uniform_sats_per_dollar\":  uniform_spd,\n",
    "            \"dynamic_sats_per_dollar\":  dynamic_spd,\n",
    "            \"uniform_percentile\":       uniform_pct,\n",
    "            \"dynamic_percentile\":       dynamic_pct,\n",
    "            \"excess_percentile\":        dynamic_pct - uniform_pct,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).set_index(\"window\")\n",
    "\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Backtest wrapper: aggregate + print SPD metrics       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def backtest_dynamic_dca(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function,\n",
    "    *,\n",
    "    strategy_label: str = \"strategy\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Runs compute_cycle_spd(...)\n",
    "    2) Prints aggregated min/max/mean/median of dynamic SPD\n",
    "    3) Prints aggregated SPD percentiles\n",
    "    4) Computes & prints exponentially-decayed average SPD and percentile\n",
    "    5) Returns the full SPD table.\n",
    "\n",
    "    Exponential decay:\n",
    "      â€¢ decay_rate âˆˆ (0,1): lower â†’ faster decay\n",
    "      â€¢ most recent window has highest weight\n",
    "      â€¢ weights normalized to sum to 1\n",
    "    \"\"\"\n",
    "    # --- run the rolling-window SPD backtest\n",
    "    spd_table   = compute_cycle_spd(dataframe, strategy_function)\n",
    "    dynamic_spd = spd_table[\"dynamic_sats_per_dollar\"]\n",
    "    dynamic_pct = spd_table[\"dynamic_percentile\"]\n",
    "\n",
    "    # --- print standard aggregated metrics\n",
    "    print(f\"\\nAggregated Metrics for {strategy_label}:\")\n",
    "    print(\"Dynamic Sats-per-Dollar:\")\n",
    "    for stat in (\"min\", \"max\", \"mean\", \"median\"):\n",
    "        val = getattr(dynamic_spd, stat)()\n",
    "        print(f\"  {stat}: {val:.2f}\")\n",
    "\n",
    "    print(\"\\nDynamic SPD Percentiles:\")\n",
    "    for stat in (\"min\", \"max\", \"mean\", \"median\"):\n",
    "        val = getattr(dynamic_pct, stat)()\n",
    "        print(f\"  {stat}: {val:.2f}%\")\n",
    "\n",
    "    # --- exponential decay weighting\n",
    "    decay_rate = 0.9\n",
    "    N = len(dynamic_spd)\n",
    "    # weight for window i (0 = oldest, N-1 = newest)\n",
    "    raw_weights = np.array([decay_rate ** (N - 1 - i) for i in range(N)])\n",
    "    exp_weights = raw_weights / raw_weights.sum()\n",
    "\n",
    "    # --- compute decayed averages\n",
    "    exp_avg_spd = (dynamic_spd.values * exp_weights).sum()\n",
    "    exp_avg_pct = (dynamic_pct.values * exp_weights).sum()\n",
    "\n",
    "    # --- print decayed metrics\n",
    "    print(f\"\\nExponential-Decay Average SPD: {exp_avg_spd:.2f}\")\n",
    "    print(f\"Exponential-Decay Average SPD Percentile: {exp_avg_pct:.2f}%\")\n",
    "\n",
    "    return spd_table\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Submission checker: forwardâ€leakage + weight & perf   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def check_strategy_submission_ready(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Sanity-check that `strategy_function`:\n",
    "      1. Uses no future data (forward-leakage test).\n",
    "      2. Produces weights â‰¥ MIN_WEIGHT.\n",
    "      3. Sums to 1.0 in each rolling window.\n",
    "      4. Outperforms uniform DCA in at least 50% of rolling windows.\n",
    "    \"\"\"\n",
    "    passed = True\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 1) Forward-leakage test\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    backtest_df  = dataframe.loc[BACKTEST_START:BACKTEST_END]\n",
    "    full_weights = strategy_function(dataframe) \\\n",
    "                       .reindex(backtest_df.index) \\\n",
    "                       .fillna(0.0)\n",
    "\n",
    "    step_dates = max(len(backtest_df) // 50, 1)\n",
    "    probe_dates = backtest_df.index[::step_dates]\n",
    "\n",
    "    for probe in probe_dates:\n",
    "        masked = dataframe.copy()\n",
    "        masked.loc[masked.index > probe, :] = np.nan\n",
    "\n",
    "        masked_wt = strategy_function(masked) \\\n",
    "                        .reindex(full_weights.index) \\\n",
    "                        .fillna(0.0)\n",
    "\n",
    "        if not np.isclose(masked_wt.loc[probe],\n",
    "                          full_weights.loc[probe],\n",
    "                          rtol=1e-9, atol=1e-12):\n",
    "            delta = abs(masked_wt.loc[probe] - full_weights.loc[probe])\n",
    "            print(f\"[{probe.date()}] âŒ Forward-leakage detected (Î”={delta:.2e})\")\n",
    "            passed = False\n",
    "            break\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 2) Weight checks per rolling window\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    window_offset = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step_freq     = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    for window_start in pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step_freq\n",
    "    ):\n",
    "        window_end = window_start + window_offset\n",
    "        label      = _make_window_label(window_start, window_end)\n",
    "\n",
    "        w_slice = strategy_function(dataframe.loc[window_start:window_end])\n",
    "\n",
    "        if (w_slice <= 0).any():\n",
    "            print(f\"[{label}] âŒ Non-positive weights detected.\")\n",
    "            passed = False\n",
    "\n",
    "        if (w_slice < MIN_WEIGHT).any():\n",
    "            print(f\"[{label}] âŒ Weight below MIN_WEIGHT = {MIN_WEIGHT}.\")\n",
    "            passed = False\n",
    "\n",
    "        total = w_slice.sum()\n",
    "        if not np.isclose(total, 1.0, rtol=1e-5, atol=1e-8):\n",
    "            print(f\"[{label}] âŒ Sum-to-1 check failed: {total:.4f}\")\n",
    "            passed = False\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 3) Performance vs. Uniform DCA (RELAXED)\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    spd_table = compute_cycle_spd(dataframe, strategy_function)\n",
    "\n",
    "    underperf_records = []\n",
    "    for label, row in spd_table.iterrows():\n",
    "        dp, up = row[\"dynamic_percentile\"], row[\"uniform_percentile\"]\n",
    "        if dp < up:\n",
    "            underperf_records.append({\n",
    "                \"Window\": label,\n",
    "                \"Dynamic Percentile\": dp,\n",
    "                \"Uniform Percentile\": up,\n",
    "                \"Delta\": dp - up\n",
    "            })\n",
    "\n",
    "    total = len(spd_table)\n",
    "    failed = len(underperf_records)\n",
    "    pass_ratio = (total - failed) / total\n",
    "\n",
    "    if underperf_records:\n",
    "        df_underperf = pd.DataFrame(underperf_records)\n",
    "        print(\"\\nâš ï¸ Windows where strategy underperformed Uniform DCA:\")\n",
    "        display(df_underperf)\n",
    "\n",
    "    print(f\"\\nSummary: Your strategy underperformed uniform DCA in {failed} out of {total} windows \"\n",
    "          f\"({100 * pass_ratio:.2f}% win rate)\")\n",
    "\n",
    "    if pass_ratio >= 0.5:\n",
    "        print(\"âœ… Strategy meets performance requirement (â‰¥ 50% win rate vs. uniform DCA).\")\n",
    "    else:\n",
    "        print(\"âŒ Strategy failed performance requirement (< 50% win rate vs. uniform DCA).\")\n",
    "        passed = False\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Final verdict\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if passed:\n",
    "        print(\"\\nâœ… Strategy is ready for submission.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Please address the above issues before submitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743eda0-d4eb-4796-8e15-01e805ee036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# core/plots.py\n",
    "# ---------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#from core.config import (\n",
    " #   BACKTEST_START,\n",
    "  #  BACKTEST_END,\n",
    "   # INVESTMENT_WINDOW,\n",
    "    #PURCHASE_FREQ,\n",
    "    #MIN_WEIGHT,\n",
    "    #PURCHASE_FREQ_TO_OFFSET,\n",
    "#)\n",
    "#from core.spd import _make_window_label\n",
    "\n",
    "\n",
    "def _get_window_index(timestamp: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Map a timestamp to its 0-based rolling-window index,\n",
    "    where windows start every PURCHASE_FREQ and span INVESTMENT_WINDOW months.\n",
    "    \"\"\"\n",
    "    window_offset = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step          = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "    valid_starts  = pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step\n",
    "    )\n",
    "    # get the position of the last valid start â‰¤ timestamp\n",
    "    idx = valid_starts.get_indexer([timestamp], method='pad')[0]\n",
    "    return int(idx)\n",
    "\n",
    "\n",
    "def plot_features(\n",
    "    df: pd.DataFrame,\n",
    "    weights: pd.Series | None = None,\n",
    "    *,\n",
    "    start_date: str | pd.Timestamp = BACKTEST_START,\n",
    "    end_date:   str | pd.Timestamp = BACKTEST_END,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot BTC price vs. the first derived feature within the chosen back-test window.\n",
    "    \"\"\"\n",
    "    df_feat = construct_features(df).loc[start_date:end_date]\n",
    "\n",
    "    if weights is not None:\n",
    "        weights = weights.loc[df_feat.index]\n",
    "\n",
    "    feature_name = df_feat.columns[1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.set_title(f\"BTC Price and {feature_name}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "    ax.plot(df_feat.index, df_feat[\"PriceUSD\"], label=\"BTC Price\", color=\"black\", alpha=0.7)\n",
    "    ax.plot(df_feat.index, df_feat[feature_name], label=feature_name, color=\"orange\", alpha=0.7)\n",
    "\n",
    "    signal = df_feat[\"PriceUSD\"] < df_feat[feature_name]\n",
    "    ax.fill_between(\n",
    "        df_feat.index,\n",
    "        df_feat[\"PriceUSD\"],\n",
    "        df_feat[feature_name],\n",
    "        where=signal,\n",
    "        color=\"green\",\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "    if weights is not None:\n",
    "        ax.scatter(\n",
    "            df_feat.index[~signal],\n",
    "            df_feat.loc[~signal, \"PriceUSD\"],\n",
    "            marker=\"o\",\n",
    "            facecolors=\"none\",\n",
    "            edgecolors=\"blue\",\n",
    "            label=\"Uniform\",\n",
    "        )\n",
    "        ax.scatter(\n",
    "            df_feat.index[signal],\n",
    "            df_feat.loc[signal, \"PriceUSD\"],\n",
    "            marker=\"o\",\n",
    "            color=\"red\",\n",
    "            label=\"Dynamic\",\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_final_weights_by_window(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_fn,\n",
    "    *,\n",
    "    window_stride: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    For each rolling window, run strategy_fn on that slice,\n",
    "    and plot the resulting weights curve (subsampled by window_stride).\n",
    "    \"\"\"\n",
    "    window_length = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step          = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "    starts        = pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_length,\n",
    "        freq=step\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "    for idx, ws in enumerate(starts):\n",
    "        if idx % window_stride != 0:\n",
    "            continue\n",
    "\n",
    "        we      = ws + window_length\n",
    "        df_win  = dataframe.loc[ws:we]\n",
    "        w_win   = strategy_fn(df_win)           # sums to 1 by design\n",
    "        label   = f\"{ws.date()} â†’ {we.date()}\"\n",
    "        color   = cmap(idx % 10)\n",
    "\n",
    "        ax.plot(w_win.index, w_win.values, label=label, color=color)\n",
    "        ax.hlines(1.0/len(w_win), w_win.index[0], w_win.index[-1],\n",
    "                  color=color, linestyle='--', alpha=0.5)\n",
    "\n",
    "    ax.axhline(MIN_WEIGHT, color='black', linestyle='--', label=f\"MIN_WEIGHT={MIN_WEIGHT}\")\n",
    "    ax.set_title(\"Weights by Rolling Window\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Weight\")\n",
    "    ax.legend(fontsize='small', ncol=2, loc='upper center')\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#######\n",
    "\n",
    "def plot_rolling_window_weight_sums(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_fn,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Re-run the strategy on each rolling window, and plot each windowâ€™s total weight\n",
    "    (should be ~1.0).\n",
    "    \"\"\"\n",
    "    window_offset = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step          = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    starts = pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step\n",
    "    )\n",
    "\n",
    "    sums = []\n",
    "    for ws in starts:\n",
    "        we         = ws + window_offset\n",
    "        df_window  = dataframe.loc[ws:we]\n",
    "        w          = strategy_fn(df_window)\n",
    "        sums.append(w.sum())\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(starts, sums, marker=\"o\", linestyle=\"-\")\n",
    "    plt.axhline(1.0, color=\"black\", linestyle=\"--\", label=\"Target = 1.0\")\n",
    "    plt.title(\"Per-Window Strategy Weight Sums (should be 1.0)\")\n",
    "    plt.xlabel(\"Window Start Date\")\n",
    "    plt.ylabel(\"Sum of Weights\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_spd_comparison(\n",
    "    spd_results: pd.DataFrame,\n",
    "    strategy_name: str = \"Dynamic\",\n",
    "    *,\n",
    "    window_stride: int = 1\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compare uniform vs dynamic DCA in sats-per-dollar and percentile space,\n",
    "    subsampling every `window_stride`-th rolling window.\n",
    "    \"\"\"\n",
    "    subs = spd_results.iloc[::window_stride]\n",
    "    x    = np.arange(len(subs))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.set_yscale(\"log\")\n",
    "\n",
    "    # Plot each line separately so we can assign colours\n",
    "    l_max, = ax1.plot(x, subs[\"max_sats_per_dollar\"],     \"o-\", color=\"green\")\n",
    "    l_dyn, = ax1.plot(x, subs[\"dynamic_sats_per_dollar\"], \"o-\", color=\"blue\")\n",
    "    l_uni, = ax1.plot(x, subs[\"uniform_sats_per_dollar\"], \"o-\", color=\"orange\")\n",
    "    l_min, = ax1.plot(x, subs[\"min_sats_per_dollar\"],     \"o-\", color=\"red\")\n",
    "\n",
    "    ax1.set_title(f\"Uniform vs {strategy_name} DCA (SPD)\")\n",
    "    ax1.set_ylabel(\"Sats per Dollar (log scale)\")\n",
    "    ax1.set_xlabel(\"Window\")\n",
    "    ax1.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(subs.index, rotation=45, ha=\"right\")\n",
    "    ax1.legend(\n",
    "        [l_max, l_dyn, l_uni, l_min],\n",
    "        [\"Max SPD\", strategy_name, \"Uniform SPD\", \"Min SPD\"],\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "\n",
    "    # Twin axis for percentiles\n",
    "    ax2 = ax1.twinx()\n",
    "    bw   = 0.4\n",
    "    ubar = ax2.bar(x - bw/2, subs[\"uniform_percentile\"],  width=bw, alpha=0.3, color='orange')\n",
    "    dbar = ax2.bar(x + bw/2, subs[\"dynamic_percentile\"], width=bw, alpha=0.3, color='blue')\n",
    "    ax2.set_ylabel(\"SPD Percentile (%)\")\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.legend([ubar, dbar], [\"Uniform %\", f\"{strategy_name} %\"], loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a88e94-246d-404d-9443-39790d9d5532",
   "metadata": {},
   "source": [
    "# âœï¸ User Code â€” Implement Your Strategy Logic Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56c6d2-67f0-4532-971a-227224be39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#from typing import Any\n",
    "#from core.config import BACKTEST_START, BACKTEST_END, INVESTMENT_WINDOW, PURCHASE_FREQ, MIN_WEIGHT\n",
    "#from core.plots  import _get_window_index\n",
    "#from core.strategies import register_strategy  # if you use strategy registration\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ADD Additional Imports under here:  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def construct_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct technical indicators used for the strategy.\n",
    "    Uses only past data for calculations to avoid look-ahead bias.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df[['PriceUSD']]\n",
    "    past_price = df['PriceUSD'].shift(1)\n",
    "    df['ma200'] = past_price.rolling(window=200, min_periods=1).mean()\n",
    "    df['std200'] = past_price.rolling(window=200, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "# Example Ethereum wallet address - replace with real one for actual submissions\n",
    "# ETH_WALLET_ADDRESS = \"0x71C7656EC7ab88b098defB751B7401B5f6d8976F\"\n",
    "\n",
    "# @register_strategy(ETH_WALLET_ADDRESS)\n",
    "\n",
    "def compute_weights(df_window: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given a 12-month slice, compute portfolio weights that sum to 1.\n",
    "    Whenever a dayâ€™s weight is â€˜boostedâ€™, redistribute the excess uniformly\n",
    "    over the last half of the window (i.e. the final ~6 months).\n",
    "    \"\"\"\n",
    "    # 1. Build feature DataFrame and index info\n",
    "    features = construct_features(df_window)\n",
    "    dates = features.index\n",
    "    total_days = len(features)\n",
    "\n",
    "    # 2. Prepare output Series\n",
    "    weights = pd.Series(index=dates, dtype=float)\n",
    "\n",
    "    # 3. Strategy parameters\n",
    "    #    PURCHASE_FREQ is one of 'Daily', 'Weekly', or 'Monthly'\n",
    "    # half of the window in rows = half of total_days\n",
    "    rebalance_window = max(total_days // 2, 1)\n",
    "    boost_alpha      = 1.25\n",
    "\n",
    "    # 4. Initialize equal weights\n",
    "    base_weight  = 1.0 / total_days\n",
    "    temp_weights = np.full(total_days, base_weight)\n",
    "\n",
    "    # 5. Extract numpy arrays for speed\n",
    "    price_array  = features[\"PriceUSD\"].values\n",
    "    ma200_array  = features[\"ma200\"].values\n",
    "    std200_array = features[\"std200\"].values\n",
    "\n",
    "    # 6. Loop through each day\n",
    "    for day_idx in range(total_days):\n",
    "        price = price_array[day_idx]\n",
    "        ma200 = ma200_array[day_idx]\n",
    "        std200 = std200_array[day_idx]\n",
    "\n",
    "        # skip if no valid signal\n",
    "        if pd.isna(ma200) or pd.isna(std200) or std200 == 0 or price >= ma200:\n",
    "            continue\n",
    "\n",
    "        # compute how far below MA200\n",
    "        z_score = (ma200 - price) / std200\n",
    "\n",
    "        # boost this dayâ€™s weight\n",
    "        boosted_weight = temp_weights[day_idx] * (1 + boost_alpha * z_score)\n",
    "        excess = boosted_weight - temp_weights[day_idx]\n",
    "\n",
    "        # redistribute excess over the last half of the window\n",
    "        start_redistribution = max(total_days - rebalance_window, day_idx + 1)\n",
    "        redistribution_indices = np.arange(start_redistribution, total_days)\n",
    "        if redistribution_indices.size == 0:\n",
    "            continue  # nothing to drain from\n",
    "\n",
    "        per_day_reduction = excess / redistribution_indices.size\n",
    "\n",
    "        # apply only if no one falls below MIN_WEIGHT\n",
    "        if np.all(temp_weights[redistribution_indices] - per_day_reduction >= MIN_WEIGHT):\n",
    "            temp_weights[day_idx] = boosted_weight\n",
    "            temp_weights[redistribution_indices] -= per_day_reduction\n",
    "        # else: skip this boost but continue looping\n",
    "\n",
    "    # 7. Assign back into a pandas Series and return\n",
    "    weights.loc[dates] = temp_weights\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ca490-39e4-4328-ad80-16975dcbd37a",
   "metadata": {},
   "source": [
    "### ğŸš« Boilerplate Code â€” Do Not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc6375-f063-45f2-b8ae-f593a0f63438",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "btc_df = load_data()\n",
    "validate_price_data(btc_df)\n",
    "btc_df = btc_df.loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "# 1) Feature plot (no weights):\n",
    "plot_features(btc_df)\n",
    "\n",
    "# 2) Final weights curvesâ€”computed per window:\n",
    "plot_final_weights_by_window(\n",
    "    btc_df,\n",
    "    compute_weights,\n",
    "    window_stride=365\n",
    ")\n",
    "\n",
    "# 3) Per-window weight-sum check:\n",
    "plot_rolling_window_weight_sums(\n",
    "    btc_df,\n",
    "    compute_weights\n",
    ")\n",
    "\n",
    "# 4) Rolling-window SPD backtest:\n",
    "df_spd = backtest_dynamic_dca(\n",
    "    btc_df,\n",
    "    compute_weights,\n",
    "    strategy_label=\"200-Day MA DCA\"\n",
    ")\n",
    "\n",
    "# 5) SPD comparison (subsampled by window_stride):\n",
    "plot_spd_comparison(\n",
    "    df_spd,\n",
    "    strategy_name=\"200-Day MA DCA\",\n",
    "    window_stride=365\n",
    ")\n",
    "\n",
    "# 6) Sanity checks (each window inside):\n",
    "check_strategy_submission_ready(btc_df, compute_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c631f-4b07-4164-943d-54025240bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate = 76.13  # insert your win rate (%)\n",
    "exp_decay_percentile = 67.17  # insert your exp-decay avg SPD percentile (%)\n",
    "\n",
    "score = 0.5 * win_rate + 0.5 * exp_decay_percentile\n",
    "print(f\"Final Model Score (50/50 weighting): {score:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-stacking-sats-env]",
   "language": "python",
   "name": "conda-env-miniconda3-stacking-sats-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
